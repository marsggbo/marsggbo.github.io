---
layout: about
title: About
permalink: /
subtitle: Research Scientist, CFAR, A*STAR, Singapore
profile:
  align: right
  image: ggbo_on_mars.jpg
  image_circular: true # crops the image to make it circular
  more_info: >
news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

hexin.research@gmail.com<br>
| [知乎](https://www.zhihu.com/people/hexin_marsggbo/posts) | [Wechat](../assets/img/WeChat.jpeg) | [博客园](https://www.cnblogs.com/marsggbo/) | [腾讯云+社区](https://cloud.tencent.com/developer/column/1851) | [Source code](https://github.com/marsggbo/marsggbo.github.io) |

I am currently a Research Scientist at A*STAR, Singapore, working with [Prof. Ong Yew Soon](https://scholar.google.com/citations?user=h9oWOsEAAAAJ&hl=en) and [Prof. Ivor W. Tsang](https://scholar.google.com.sg/citations?user=rJMOlVsAAAAJ&hl=en). Prior to this, I completed my Ph.D. in Computer Science at Hong Kong Baptist University (HKBU), where I was advised by [Prof. Chu Xiaowen](https://sites.google.com/view/chuxiaowen). I earned my Bachelor's degree with honors in the School of Electronic Information and Communications at Huazhong University of Science & Technology (HUST).


Driven by a mission to democratize deep learning, my research is dedicated to advancing the accessibility and efficiency of large-scale deep learning models, particularly Large Language Models (LLMs). My goal is to bridge the theoretical aspects of machine learning with practical system designs to create scalable, robust, and trustworthy AI systems that are widely accessible. My interested research directions include:
- 1.**Model-Centric AI**:
  - Architecture Dearch: Neural Architecture Search (e.g., multi-objective NAS, Training-free NAS, resource-aware NAS), Sparse Model (e.g., Mixture-of-Experts)
  - Hyper-parameter optimization (HPO): Grid/Random Search, Evolutionary Algorithm, Differentiable Optimization
  - Model Compression: Pruning, Quantization, Knowledge Distillation
- 2.**Data-Centric AI**:
  - Automatic Data Augmentation (ADA), Data Generation, Dataset compression,
  - RAG, LLM alignment
- 3.**HPC AI**:
  - Memory efficiency: Offloading, KV-cache
  - LLM training acceleration: Distributed Parallellism (data parallel, tensor parallel, pipeline parallel)
  - LLM inference optimization: Batch Schedule, Dynamic Inference Paths


*Interested in collaboration? <a href = "mailto: hexin.research@gmail.com">Contact me</a>.*


#### Highlights

- 1.AutoML Survey (**1770+ citation**): [AutoML: A Survey of State-of-ther-art](https://arxiv.org/abs/1908.00709)
- 2.AutoML Framework: [Hyperbox](https://github.com/marsggbo/hyperbox) [![Hyperbox](https://img.shields.io/github/stars/marsggbo/hyperbox?style=social)](https://github.com/marsggbo/hyperbox)
- 3.AutoML Applications: 
  - [AAAI2021 COVID3DNet](https://ojs.aaai.org/index.php/AAAI/article/view/16614): The first NAS application for COVID-19 3D CT scans
  - [MICCAI2022 EMARS](https://dl.acm.org/doi/abs/10.1007/978-3-031-16431-6_53): Evolutionary algorithm-based NAS for COVID-19 3D CT scans
  - [ECCV2022 EAGAN](https://arxiv.org/abs/2111.15097): Two-stage NAS for GANs
  - [AAAI2023 NAS-LID](https://arxiv.org/abs/2211.12759): NAS with Local Intrinsic Dimension

