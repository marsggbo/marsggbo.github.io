<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://marsggbo.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://marsggbo.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-30T06:14:13+00:00</updated><id>https://marsggbo.github.io/feed.xml</id><title type="html">MARSGGBO’s World</title><subtitle>SSS: Study, Sleep, Slim</subtitle><entry><title type="html">vLLM 源码解析（一）</title><link href="https://marsggbo.github.io/blog/2024/vllm-%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/" rel="alternate" type="text/html" title="vLLM 源码解析（一）"/><published>2024-02-04T16:40:16+00:00</published><updated>2024-02-04T16:40:16+00:00</updated><id>https://marsggbo.github.io/blog/2024/vllm%20%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88</id><content type="html" xml:base="https://marsggbo.github.io/blog/2024/vllm-%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/"><![CDATA[<h1 id="1-quick-start">1. Quick Start</h1> <p>创建如下代码，命名为 <code class="language-plaintext highlighter-rouge">run.py</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">vllm</span> <span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">SamplingParams</span>

<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
	<span class="sh">"</span><span class="s">Have you followed marsggbo in Zhihu?</span><span class="sh">"</span><span class="p">,</span>
	<span class="sh">"</span><span class="s">你一键三连了吗？</span><span class="sh">"</span>
<span class="p">]</span> <span class="c1"># 输入prompts
</span><span class="n">sampling_params</span> <span class="o">=</span> <span class="nc">SamplingParams</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span> <span class="c1"># 采样策略
</span><span class="n">llm</span> <span class="o">=</span> <span class="nc">LLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">facebook/opt-125m</span><span class="sh">"</span><span class="p">,</span> <span class="n">tensor_parallel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># 初始化 LLM
</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span> <span class="c1"># 完成推理
</span><span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
	<span class="n">prompt</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">prompt</span>
    <span class="n">generated_text</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">text</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">!r}</span><span class="s">, Generated text: </span><span class="si">{</span><span class="n">generated_text</span><span class="si">!r}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>执行命令：<code class="language-plaintext highlighter-rouge">python run.py</code>。该脚本会自动将模型以张量并行的方式在两个 GPU 上进行推理计算。</p> <p>整个推理过程大大致流程如下图所示，即</p> <ul> <li>1 给定一定数量的 prompts（字符串数组）</li> <li> <ol> <li>vllm 会使用 Scheduler 模块自动对需要推理句子进行调度</li> </ol> </li> <li> <ol> <li>根据调度的结果，使用 tokenizer 将字符串转换成 prompt id，然后喂给 model 进行计算得到 logits 预测结果</li> </ol> </li> <li> <ol> <li>根据 logits 预测结果和提前设置好的采样策略对结果进行采样得到新的 token id</li> </ol> </li> <li> <ol> <li>将采样结果保存到 output</li> </ol> </li> </ul> <p><img src="https://raw.githubusercontent.com/marsggbo/PicBed/master/小书匠/2024_2_4_1707030203438.png" alt="inferencce pipeline"/></p> <h1 id="2-整体核心模块">2. 整体核心模块</h1> <p><img src="https://raw.githubusercontent.com/marsggbo/PicBed/master/小书匠/2024_2_4_1707037549078.png" alt="vllm 核心模块结构"/></p> <p>上图给出了 vLLM 核心模块之间的结构关系。接下来我们从简单的模块（即输入、采样和输出）开始介绍，最后详细介绍 LLM 模块。</p> <h1 id="3-sequence">3. Sequence</h1> <p><img src="https://raw.githubusercontent.com/marsggbo/PicBed/master/小书匠/2024_2_4_1707031824422.png" alt="句子模块"/></p> <p>如上图我们可以看到 vLLM 为输入的句子设计了很多子模块，这些模块的用处各不相同，但是有彼此之间有关系，下面分别详细介绍一下。</p> <h1 id="31-sequencestatus">3.1 SequenceStatus</h1> <p>首先看到 <code class="language-plaintext highlighter-rouge">SequenceStatus</code>，其源代码如下：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SequenceStatus</span><span class="p">(</span><span class="n">enum</span><span class="p">.</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Status of a sequence.</span><span class="sh">"""</span>
    <span class="n">WAITING</span> <span class="o">=</span> <span class="n">enum</span><span class="p">.</span><span class="nf">auto</span><span class="p">()</span> <span class="c1"># 等待中，句子还没开始推理，或者推理还未结束
</span>    <span class="n">RUNNING</span> <span class="o">=</span> <span class="n">enum</span><span class="p">.</span><span class="nf">auto</span><span class="p">()</span> <span class="c1"># 运行中
</span>    <span class="n">SWAPPED</span> <span class="o">=</span> <span class="n">enum</span><span class="p">.</span><span class="nf">auto</span><span class="p">()</span> <span class="c1"># 已交换
</span>    <span class="n">FINISHED_STOPPED</span> <span class="o">=</span> <span class="n">enum</span><span class="p">.</span><span class="nf">auto</span><span class="p">()</span> <span class="c1"># 已停止
</span>    <span class="n">FINISHED_LENGTH_CAPPED</span> <span class="o">=</span> <span class="n">enum</span><span class="p">.</span><span class="nf">auto</span><span class="p">()</span> <span class="c1"># 已长度限制
</span>    <span class="n">FINISHED_ABORTED</span> <span class="o">=</span> <span class="n">enum</span><span class="p">.</span><span class="nf">auto</span><span class="p">()</span> <span class="c1"># 已中止
</span>    <span class="n">FINISHED_IGNORED</span> <span class="o">=</span> <span class="n">enum</span><span class="p">.</span><span class="nf">auto</span><span class="p">()</span> <span class="c1"># 已忽略
</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">is_finished</span><span class="p">(</span><span class="n">status</span><span class="p">:</span> <span class="sh">"</span><span class="s">SequenceStatus</span><span class="sh">"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="c1"># 判断状态是否为已停止、已长度限制、已中止或已忽略
</span>        <span class="k">return</span> <span class="n">status</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="n">SequenceStatus</span><span class="p">.</span><span class="n">FINISHED_STOPPED</span><span class="p">,</span>
            <span class="n">SequenceStatus</span><span class="p">.</span><span class="n">FINISHED_LENGTH_CAPPED</span><span class="p">,</span>
            <span class="n">SequenceStatus</span><span class="p">.</span><span class="n">FINISHED_ABORTED</span><span class="p">,</span>
            <span class="n">SequenceStatus</span><span class="p">.</span><span class="n">FINISHED_IGNORED</span><span class="p">,</span>
        <span class="p">]</span>
</code></pre></div></div> <h2 id="32-sequencedata">3.2 SequenceData</h2> <p><code class="language-plaintext highlighter-rouge">SequenceData</code> 用于存储与序列相关的数据。这个类有三个属性：<code class="language-plaintext highlighter-rouge">prompt_token_ids</code>（提示词的标记ID）、<code class="language-plaintext highlighter-rouge">output_token_ids</code>（生成文本的标记ID）和<code class="language-plaintext highlighter-rouge">cumulative_logprob</code>（累计对数概率）。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SequenceData</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">prompt_token_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">prompt_token_ids</span> <span class="o">=</span> <span class="n">prompt_token_ids</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_token_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cumulative_logprob</span> <span class="o">=</span> <span class="mf">0.0</span>
</code></pre></div></div> <h2 id="33-sequence">3.3 Sequence</h2> <p><code class="language-plaintext highlighter-rouge">Sequence</code> 用于存储序列的数据、状态和块信息,且每个序列有唯一标识，即<code class="language-plaintext highlighter-rouge">seq_id</code>。注意看下面的代码：</p> <ul> <li><strong>数据</strong>其实是通过上面的 <code class="language-plaintext highlighter-rouge">SequenceData</code> 保存的</li> <li>默认初始化状态，所有句子序列的<strong>状态</strong>都是 <code class="language-plaintext highlighter-rouge">SequenceStatus.WAITING</code></li> <li>所谓<strong>块信息</strong>，其实就是 vLLM 会在初始化阶段预留出一定数量的CPU 和 GPU 内存，一般是以 token 为单位的，例如在初始化的时候会使用值全为 0，大小为 (256, 128)的 prompt_ids做 warm up。每个序列会按照实际大小申请 block 来记录内存使用情况，即序列 token 数越多，属性<code class="language-plaintext highlighter-rouge">logical_token_blocks</code>包含的 block 个数也就越多。</li> <li> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Sequence</span><span class="p">:</span>
<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
    <span class="n">self</span><span class="p">,</span>
    <span class="n">seq_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">prompt_token_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">block_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">self</span><span class="p">.</span><span class="n">seq_id</span> <span class="o">=</span> <span class="n">seq_id</span>
    <span class="n">self</span><span class="p">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span>
    <span class="n">self</span><span class="p">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">block_size</span>

    <span class="n">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="nc">SequenceData</span><span class="p">(</span><span class="n">prompt_token_ids</span><span class="p">)</span> <span class="c1"># 数据
</span>
    <span class="n">self</span><span class="p">.</span><span class="n">logical_token_blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">LogicalTokenBlock</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Initialize the logical token blocks with the prompt token ids.
</span>    <span class="n">self</span><span class="p">.</span><span class="nf">_append_tokens_to_blocks</span><span class="p">(</span><span class="n">prompt_token_ids</span><span class="p">)</span> <span class="c1"># 块信息
</span>    <span class="n">self</span><span class="p">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">SequenceStatus</span><span class="p">.</span><span class="n">WAITING</span> <span class="c1"># 状态
</span>    <span class="bp">...</span>
</code></pre></div> </div> </li> </ul> <h2 id="33-sequencegroup">3.3 SequenceGroup</h2> <p><code class="language-plaintext highlighter-rouge">Sequence</code>只是单个序列的表示方式,<code class="language-plaintext highlighter-rouge">seq_id</code>是它的唯一标识。<code class="language-plaintext highlighter-rouge">SequenceGroup</code>则是为了表示多个序列，<code class="language-plaintext highlighter-rouge">request_id</code>是它的唯一标识，表示是第几个请求。</p> <p>具体而言，可以看到<code class="language-plaintext highlighter-rouge">__init__</code>函数有个参数是 <code class="language-plaintext highlighter-rouge">seqs: List[Sequence]</code>，它表示由一个或多个 Sequence 组成的列表，然后会通过<code class="language-plaintext highlighter-rouge">self.seqs_dict = {seq.seq_id: seq for seq in seqs}</code>转化成字典方便管理，这个字典的 key 是每个 Sequence 的唯一标识<code class="language-plaintext highlighter-rouge">seq_id</code>。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SequenceGroup</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">request_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">seqs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Sequence</span><span class="p">],</span>
        <span class="n">sampling_params</span><span class="p">:</span> <span class="n">SamplingParams</span><span class="p">,</span>
        <span class="n">arrival_time</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">lora_request</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LoRARequest</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Prefix</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">request_id</span> <span class="o">=</span> <span class="n">request_id</span>
        <span class="n">self</span><span class="p">.</span><span class="n">seqs_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">seq</span><span class="p">.</span><span class="n">seq_id</span><span class="p">:</span> <span class="n">seq</span> <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">seqs</span><span class="p">}</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sampling_params</span> <span class="o">=</span> <span class="n">sampling_params</span>
        <span class="n">self</span><span class="p">.</span><span class="n">arrival_time</span> <span class="o">=</span> <span class="n">arrival_time</span>
		<span class="bp">...</span>
</code></pre></div></div> <p>下面是 vLLm 中 LLMEngine 使用 Sequence 和 SequenceGroup 的场景示例：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LLMEngine</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">add_request</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">request_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">sampling_params</span><span class="p">:</span> <span class="n">SamplingParams</span><span class="p">,</span>
        <span class="n">prompt_token_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">arrival_time</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">lora_request</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LoRARequest</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">prefix_pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">prompt_token_ids</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encode_request</span><span class="p">(</span>
            <span class="n">request_id</span><span class="o">=</span><span class="n">request_id</span><span class="p">,</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">prompt_token_ids</span><span class="o">=</span><span class="n">prompt_token_ids</span><span class="p">,</span>
            <span class="n">lora_request</span><span class="o">=</span><span class="n">lora_request</span><span class="p">)</span> <span class="c1"># 将字符串序列转换成 id
</span>
        <span class="c1"># Create the sequences.
</span>        <span class="n">block_size</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">cache_config</span><span class="p">.</span><span class="n">block_size</span>
        <span class="n">seq_id</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">seq_counter</span><span class="p">)</span>
        <span class="n">seq</span> <span class="o">=</span> <span class="nc">Sequence</span><span class="p">(</span><span class="n">seq_id</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">prompt_token_ids</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span>
                       <span class="n">lora_request</span><span class="p">)</span>

        <span class="c1"># Create the sequence group.
</span>        <span class="n">seq_group</span> <span class="o">=</span> <span class="nc">SequenceGroup</span><span class="p">(</span><span class="n">request_id</span><span class="p">,</span> <span class="p">[</span><span class="n">seq</span><span class="p">],</span> <span class="n">sampling_params</span><span class="p">,</span>
                                  <span class="n">arrival_time</span><span class="p">)</span>

        <span class="c1"># Add the sequence group to the scheduler.
</span>        <span class="n">self</span><span class="p">.</span><span class="n">scheduler</span><span class="p">.</span><span class="nf">add_seq_group</span><span class="p">(</span><span class="n">seq_group</span><span class="p">)</span>
</code></pre></div></div> <p>可以看到<code class="language-plaintext highlighter-rouge">SequenceGroup</code>的<code class="language-plaintext highlighter-rouge">seqs</code>参数在最初阶段其实只是单个序列 ，即<code class="language-plaintext highlighter-rouge">[seq]</code>。但是我们知道其实一个 prompt 可以有多个输出结果，所以<code class="language-plaintext highlighter-rouge">SequenceGroup</code>的目的是管理一个输入 prompt的多个生成序列信息。如果我们设置<code class="language-plaintext highlighter-rouge">SamplingParams.n=2</code>（第 4 节会介绍），那么在推理过程中，<code class="language-plaintext highlighter-rouge">SequenceGroup</code>会新增一个 Sequence，这个新增的 Sequence 的 seq_id 和原来的那个 Sequence 不一样，具体的代码细节会在下一篇文章中介绍。</p> <h2 id="35-sequencegroupmetadata">3.5 SequenceGroupMetadata</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SequenceGroupMetadata</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">request_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">is_prompt</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">seq_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">SequenceData</span><span class="p">],</span>
        <span class="n">sampling_params</span><span class="p">:</span> <span class="n">SamplingParams</span><span class="p">,</span>
        <span class="n">block_tables</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">request_id</span> <span class="o">=</span> <span class="n">request_id</span>
        <span class="n">self</span><span class="p">.</span><span class="n">is_prompt</span> <span class="o">=</span> <span class="n">is_prompt</span>
        <span class="n">self</span><span class="p">.</span><span class="n">seq_data</span> <span class="o">=</span> <span class="n">seq_data</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sampling_params</span> <span class="o">=</span> <span class="n">sampling_params</span>
        <span class="n">self</span><span class="p">.</span><span class="n">block_tables</span> <span class="o">=</span> <span class="n">block_tables</span>
		<span class="bp">...</span>
</code></pre></div></div> <p>SequenceGroupMetadata 记录了一些元信息，下面代码展示了 Scheduler 模块是如何生成这些信息的：</p> <ul> <li><code class="language-plaintext highlighter-rouge">request_id</code> 就是 SequenceGroup的 request_id</li> <li><code class="language-plaintext highlighter-rouge">seq_data</code> 是一个字典，key 是每个 Sequence的 seq_id，value 则是对应的 data （即 SequenceData）</li> <li><code class="language-plaintext highlighter-rouge">block_tables</code>也是一个字典，key 也是每个 Sequence的 seq_id，value 这是对应 Sequence 申请的 block</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Scheduler</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">schedule</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">SequenceGroupMetadata</span><span class="p">],</span> <span class="n">SchedulerOutputs</span><span class="p">]:</span>
        <span class="n">scheduler_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_schedule</span><span class="p">()</span>

        <span class="c1"># Create input data structures.
</span>        <span class="n">seq_group_metadata_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SequenceGroupMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">seq_group</span> <span class="ow">in</span> <span class="n">scheduler_outputs</span><span class="p">.</span><span class="n">scheduled_seq_groups</span><span class="p">:</span>
            <span class="n">seq_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">SequenceData</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">block_tables</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">seq_group</span><span class="p">.</span><span class="nf">get_seqs</span><span class="p">(</span><span class="n">status</span><span class="o">=</span><span class="n">SequenceStatus</span><span class="p">.</span><span class="n">RUNNING</span><span class="p">):</span>
                <span class="n">seq_id</span> <span class="o">=</span> <span class="n">seq</span><span class="p">.</span><span class="n">seq_id</span>
                <span class="n">seq_data</span><span class="p">[</span><span class="n">seq_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">seq</span><span class="p">.</span><span class="n">data</span> <span class="c1"># 单个 SequenceData
</span>                <span class="n">block_tables</span><span class="p">[</span><span class="n">seq_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">block_manager</span><span class="p">.</span><span class="nf">get_block_table</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="c1"># 对应Sequence的block信息
</span>
            <span class="n">seq_group_metadata</span> <span class="o">=</span> <span class="nc">SequenceGroupMetadata</span><span class="p">(</span>
                <span class="n">request_id</span><span class="o">=</span><span class="n">seq_group</span><span class="p">.</span><span class="n">request_id</span><span class="p">,</span>
                <span class="n">is_prompt</span><span class="o">=</span><span class="n">scheduler_outputs</span><span class="p">.</span><span class="n">prompt_run</span><span class="p">,</span>
                <span class="n">seq_data</span><span class="o">=</span><span class="n">seq_data</span><span class="p">,</span>
                <span class="n">sampling_params</span><span class="o">=</span><span class="n">seq_group</span><span class="p">.</span><span class="n">sampling_params</span><span class="p">,</span>
                <span class="n">block_tables</span><span class="o">=</span><span class="n">block_tables</span><span class="p">,</span>
                <span class="n">lora_request</span><span class="o">=</span><span class="n">seq_group</span><span class="p">.</span><span class="n">lora_request</span><span class="p">,</span>
                <span class="n">prefix</span><span class="o">=</span><span class="n">seq_group</span><span class="p">.</span><span class="n">prefix</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">seq_group_metadata_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">seq_group_metadata</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">seq_group_metadata_list</span><span class="p">,</span> <span class="n">scheduler_outputs</span>
</code></pre></div></div> <h2 id="36-sequenceoutput-和-sequencegroupoutput">3.6 SequenceOutput 和 SequenceGroupOutput</h2> <p>SequenceOutput 和 SequenceGroupOutput的关系就类似 Sequence 和 SequenceGroup。SequenceOutput其实就是记录了上一个 输入 token id 以及对应输出的 token id。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SequenceOutput</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">parent_seq_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_token</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">logprobs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">parent_seq_id</span> <span class="o">=</span> <span class="n">parent_seq_id</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_token</span> <span class="o">=</span> <span class="n">output_token</span>
        <span class="n">self</span><span class="p">.</span><span class="n">logprobs</span> <span class="o">=</span> <span class="n">logprobs</span>

<span class="k">class</span> <span class="nc">SequenceGroupOutput</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">samples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SequenceOutput</span><span class="p">],</span>
        <span class="n">prompt_logprobs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PromptLogprobs</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span>
        <span class="n">self</span><span class="p">.</span><span class="n">prompt_logprobs</span> <span class="o">=</span> <span class="n">prompt_logprobs</span>
</code></pre></div></div> <h1 id="4-samplingparams">4. SamplingParams</h1> <p><img src="https://raw.githubusercontent.com/marsggbo/PicBed/master/小书匠/2024_2_4_1707037767316.png" alt="SamplingParams"/></p> <p>SamplingParams 包含以下参数：</p> <ul> <li><code class="language-plaintext highlighter-rouge">n</code>：要生成的序列的数量，默认为 1。</li> <li><code class="language-plaintext highlighter-rouge">best_of</code>：从多少个序列中选择最佳序列，需要大于 n，默认等于 n。</li> <li><code class="language-plaintext highlighter-rouge">temperature</code>：用于控制生成结果的随机性，较低的温度会使生成结果更确定性，较高的温度会使生成结果更随机。</li> <li><code class="language-plaintext highlighter-rouge">top_p</code>：用于过滤掉生成词汇表中概率低于给定阈值的词汇，控制随机性。</li> <li><code class="language-plaintext highlighter-rouge">top_k</code>：选择前 k 个候选 token，控制多样性。</li> <li><code class="language-plaintext highlighter-rouge">presence_penalty</code>：用于控制生成结果中特定词汇的出现频率。</li> <li><code class="language-plaintext highlighter-rouge">frequency_penalty</code>：用于控制生成结果中词汇的频率分布。</li> <li><code class="language-plaintext highlighter-rouge">repetition_penalty</code>：用于控制生成结果中的词汇重复程度。</li> <li><code class="language-plaintext highlighter-rouge">use_beam_search</code>：是否使用束搜索来生成序列。</li> <li><code class="language-plaintext highlighter-rouge">length_penalty</code>：用于控制生成结果的长度分布。</li> <li><code class="language-plaintext highlighter-rouge">early_stopping</code>：是否在生成过程中提前停止。</li> <li><code class="language-plaintext highlighter-rouge">stop</code>：要停止生成的词汇列表。</li> <li><code class="language-plaintext highlighter-rouge">stop_token_ids</code>：要停止生成的词汇的ID列表。</li> <li><code class="language-plaintext highlighter-rouge">include_stop_str_in_output</code>：是否在输出结果中包含停止字符串。</li> <li><code class="language-plaintext highlighter-rouge">ignore_eos</code>：在生成过程中是否忽略结束符号。</li> <li><code class="language-plaintext highlighter-rouge">max_tokens</code>：生成序列的最大长度。</li> <li><code class="language-plaintext highlighter-rouge">logprobs</code>：用于记录生成过程的概率信息。</li> <li><code class="language-plaintext highlighter-rouge">prompt_logprobs</code>：用于记录生成过程的概率信息，用于特定提示。</li> <li><code class="language-plaintext highlighter-rouge">skip_special_tokens</code>：是否跳过特殊符号。</li> <li><code class="language-plaintext highlighter-rouge">spaces_between_special_tokens</code>：是否在特殊符号之间添加空格。</li> </ul> <p>这些参数的设置通常取决于具体需求和模型性能。以下是一些常见的设置指导方法：</p> <ul> <li><code class="language-plaintext highlighter-rouge">temperature</code>：较低的温度（如0.2）会产生更确定性的结果，而较高的温度（如0.8）会产生更随机的结果。您可以根据您的需求进行调整。</li> <li><code class="language-plaintext highlighter-rouge">presence_penalty、frequency_penalty 和 repetition_penalty</code>：这些参数可以用于控制生成结果中的词汇分布和重复程度。您可以根据您的需求进行调整。</li> <li><code class="language-plaintext highlighter-rouge">use_beam_search</code>：束搜索通常用于生成更高质量的结果，但可能会降低生成速度。您可以根据您的需求进行调整。</li> <li><code class="language-plaintext highlighter-rouge">length_penalty</code>：这个参数可以用于控制生成结果的长度。较高的值会产生更长的结果，而较低的值会产生更短的结果。您可以根据您的需求进行调整。</li> <li><code class="language-plaintext highlighter-rouge">early_stopping</code>：如果您不希望生成过长的结果，可以设置此参数为True。</li> <li><code class="language-plaintext highlighter-rouge">stop 和 stop_token_ids</code>：您可以使用这些参数来指定生成结果的结束条件。</li> </ul> <h1 id="5-output-模块">5. Output 模块</h1> <p><img src="https://raw.githubusercontent.com/marsggbo/PicBed/master/小书匠/2024_2_4_1707040962845.png" alt="Output模块"/></p> <p>Output 主要用于表示语言模型（LLM）的生成结果，包含如下两个模块：</p> <ul> <li><code class="language-plaintext highlighter-rouge">CompletionOutput</code></li> <li><code class="language-plaintext highlighter-rouge">RequestOutput</code></li> </ul> <p>通过上面的介绍我们知道一个 request 可能包含多个序列，<code class="language-plaintext highlighter-rouge">CompletionOutput</code> 用来表示一个 request 中某个序列的完整输出的数据，其中下面的<code class="language-plaintext highlighter-rouge">index</code>就表示该序列在 request 中的索引位置</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CompletionOutput</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="c1"># 输出结果在请求中的索引
</span>        <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="c1"># 生成的文本
</span>        <span class="n">token_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="c1"># 生成的文本对应的 token ID 列表
</span>        <span class="n">cumulative_logprob</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">logprobs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SampleLogprobs</span><span class="p">],</span>
        <span class="n">finish_reason</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="c1"># 序列完成的原因（SequenceStatus）
</span>        <span class="n">lora_request</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LoRARequest</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">index</span>
        <span class="n">self</span><span class="p">.</span><span class="n">text</span> <span class="o">=</span> <span class="n">text</span>
        <span class="n">self</span><span class="p">.</span><span class="n">token_ids</span> <span class="o">=</span> <span class="n">token_ids</span>
        <span class="n">self</span><span class="p">.</span><span class="n">finish_reason</span> <span class="o">=</span> <span class="n">finish_reason</span>
		<span class="bp">...</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">RequestOutput</code>则表示 request 所有序列的输出结果，有它的初始化函数可以看到它记录了对应的 <code class="language-plaintext highlighter-rouge">request_id</code>。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RequestOutput</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">request_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">prompt_token_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">prompt_logprobs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PromptLogprobs</span><span class="p">],</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">CompletionOutput</span><span class="p">],</span>
        <span class="n">finished</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">lora_request</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LoRARequest</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">self</span><span class="p">.</span><span class="n">request_id</span> <span class="o">=</span> <span class="n">request_id</span>
        <span class="n">self</span><span class="p">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span>
        <span class="n">self</span><span class="p">.</span><span class="n">prompt_token_ids</span> <span class="o">=</span> <span class="n">prompt_token_ids</span>
        <span class="n">self</span><span class="p">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span>
        <span class="n">self</span><span class="p">.</span><span class="n">finished</span> <span class="o">=</span> <span class="n">finished</span>
		<span class="bp">...</span>
</code></pre></div></div> <p>我们看看RequestOutput的from_seq_group就能很好理解<code class="language-plaintext highlighter-rouge">CompletionOutput</code>和 <code class="language-plaintext highlighter-rouge">RequestOutput</code>是如何使用的了。为方便理解，代码有删减，但是不影响最终结果：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RequestOutput</span><span class="p">:</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_seq_group</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">seq_group</span><span class="p">:</span> <span class="n">SequenceGroup</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="sh">"</span><span class="s">RequestOutput</span><span class="sh">"</span><span class="p">:</span>
        <span class="c1"># 1. Get the top-n sequences.
</span>        <span class="n">n</span> <span class="o">=</span> <span class="n">seq_group</span><span class="p">.</span><span class="n">sampling_params</span><span class="p">.</span><span class="n">n</span> <span class="c1"># 每个序列返回的生成序列数量
</span>        <span class="n">seqs</span> <span class="o">=</span> <span class="n">seq_group</span><span class="p">.</span><span class="nf">get_seqs</span><span class="p">()</span>
		<span class="c1"># 根据累积 logprob 值来选择出前 n 个生成序列
</span>		<span class="n">sorting_key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">seq</span><span class="p">:</span> <span class="n">seq</span><span class="p">.</span><span class="nf">get_cumulative_logprob</span><span class="p">()</span>
        <span class="n">sorted_seqs</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">seqs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">sorting_key</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">top_n_seqs</span> <span class="o">=</span> <span class="n">sorted_seqs</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>

        <span class="c1"># 2. Create the outputs.
</span>        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">CompletionOutput</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">top_n_seqs</span><span class="p">:</span>
            <span class="n">logprobs</span> <span class="o">=</span> <span class="n">seq</span><span class="p">.</span><span class="n">output_logprobs</span>
            <span class="n">finshed_reason</span> <span class="o">=</span> <span class="n">SequenceStatus</span><span class="p">.</span><span class="nf">get_finished_reason</span><span class="p">(</span><span class="n">seq</span><span class="p">.</span><span class="n">status</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="nc">CompletionOutput</span><span class="p">(</span><span class="n">seqs</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span><span class="n">seq</span><span class="p">),</span> <span class="n">seq</span><span class="p">.</span><span class="n">output_text</span><span class="p">,</span>
                                      <span class="n">seq</span><span class="p">.</span><span class="nf">get_output_token_ids</span><span class="p">(),</span>
                                      <span class="n">seq</span><span class="p">.</span><span class="nf">get_cumulative_logprob</span><span class="p">(),</span> <span class="n">logprobs</span><span class="p">,</span>
                                      <span class="n">finshed_reason</span><span class="p">)</span>
            <span class="n">outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="c1"># Every sequence in the sequence group should have the same prompt.
</span>        <span class="n">prompt</span> <span class="o">=</span> <span class="n">seq_group</span><span class="p">.</span><span class="n">prompt</span>
        <span class="n">prompt_token_ids</span> <span class="o">=</span> <span class="n">seq_group</span><span class="p">.</span><span class="n">prompt_token_ids</span>
        <span class="n">prompt_logprobs</span> <span class="o">=</span> <span class="n">seq_group</span><span class="p">.</span><span class="n">prompt_logprobs</span>
        <span class="n">finished</span> <span class="o">=</span> <span class="n">seq_group</span><span class="p">.</span><span class="nf">is_finished</span><span class="p">()</span>
        <span class="k">return</span> <span class="nf">cls</span><span class="p">(</span><span class="n">seq_group</span><span class="p">.</span><span class="n">request_id</span><span class="p">,</span>
                   <span class="n">prompt</span><span class="p">,</span>
                   <span class="n">prompt_token_ids</span><span class="p">,</span>
                   <span class="n">prompt_logprobs</span><span class="p">,</span>
                   <span class="n">outputs</span><span class="p">,</span>
                   <span class="n">finished</span><span class="p">,</span>
                   <span class="n">lora_request</span><span class="o">=</span><span class="n">seq_group</span><span class="p">.</span><span class="n">lora_request</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">RequestOutput</code>是通过对传入的<code class="language-plaintext highlighter-rouge">seq_group: SequenceGroup</code>进行解析后得到的。解析过程主要有两个阶段：</p> <ul> <li> <ol> <li>Get the top-n sequences：这一阶段就是对生成序列按照 cumulative_logprob 进行排序，最后选择出top-n 序列。</li> </ol> </li> <li> <ol> <li>Create the outputs：将所有top-n生成序列分别转换成 <code class="language-plaintext highlighter-rouge">CompletionOutput</code>列表，并作为<code class="language-plaintext highlighter-rouge">RequestOutput</code>的初始化参数。</li> </ol> </li> </ul> <footer style="color:white;;background-color:rgb(24,24,24);padding:10px;border-radius:10px;"> <h3 style="text-align:center;color:tomato;font-size:16px;" id="autoid-2-0-0"> <center> <span>微信公众号：AutoML机器学习</span><br/> <img src="https://pic4.zhimg.com/80/v2-87083e55cd41dbef83cc840c142df48a_720w.jpeg" style="width:200px;height:200px"/> </center> <b>MARSGGBO</b><b style="color:white;"><span style="font-size:25px;">♥</span>原创</b><br/> <span>如有意合作或学术讨论欢迎私戳联系~<br/>邮箱:marsggbo@foxmail.com</span> <b style="color:white;"><br/> </b><p><b style="color:white;"></b> </p></h3> </footer>]]></content><author><name></name></author><category term="techniques"/><category term="LLM"/><category term="Serving"/><category term="vLLM"/><category term="大模型推理"/><summary type="html"><![CDATA[1. Quick Start]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://marsggbo.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://marsggbo.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://marsggbo.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>